{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_05-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjakkani1015/rashmi_INFO5731_-Fall2021/blob/main/In_class_exercise_05_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceAHKzEEDodm"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SctB-zvDodp"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X2_iUlFDodq",
        "outputId": "8441cd77-515b-4d27-bd06-98c3505cb19d"
      },
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "\n",
        "Traindataframe = pd.read_csv(r'/content/stsa-train.txt',sep = 'delimiter=',header= None,names=['abstract'])\n",
        "Testdataframe = pd.read_csv(r'/content/stsa-test.txt',sep = 'delimiter=',header= None,names=['abstract'])\n",
        "\n",
        "Traindataframe[['Sentiment','abstract']] = Traindataframe[\"abstract\"].str.split(\" \", 1, expand=True)\n",
        "Testdataframe[['Sentiment','astract']] = Testdataframe[\"abstract\"].str.split(\" \", 1, expand=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW7ZEMo3gnDK",
        "outputId": "6b71f5db-6a55-4a6a-89bb-33ab2eccc891"
      },
      "source": [
        "print(Traindataframe.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            abstract Sentiment\n",
            "0  a stirring , funny and finally transporting re...         1\n",
            "1  apparently reassembled from the cutting-room f...         0\n",
            "2  they presume their audience wo n't sit still f...         0\n",
            "3  this is a visually stunning rumination on love...         1\n",
            "4  jonathan parker 's bartleby should have been t...         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TBI6aiNgyTf",
        "outputId": "f5f66855-3002-4104-e720-ceb3f404fce6"
      },
      "source": [
        "print(Testdataframe.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            abstract  ...                                            astract\n",
            "0   0 no movement , no yuks , not much of anything .  ...     no movement , no yuks , not much of anything .\n",
            "1  0 a gob of drivel so sickly sweet , even the e...  ...  a gob of drivel so sickly sweet , even the eag...\n",
            "2  0 gangs of new york is an unapologetic mess , ...  ...  gangs of new york is an unapologetic mess , wh...\n",
            "3  0 we never really feel involved with the story...  ...  we never really feel involved with the story ,...\n",
            "4          1 this is one of polanski 's best films .  ...            this is one of polanski 's best films .\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDt0ffb_sgq-",
        "outputId": "711d9a4c-1236-40a4-e45f-3c508b695f70"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "sw = nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "WL= WordNetLemmatizer()\n",
        "\n",
        "def cleaneddata(T):\n",
        "  T =\"\".join([word.lower() for word in T if word not in string.punctuation])\n",
        "  T = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", T)\n",
        "  phrases = re.split('\\W+',T)\n",
        "  T = [WL.lemmatize(word) for word in phrases if word not in sw]\n",
        "  return T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGqCLRNOuEVp",
        "outputId": "da6fbc2f-41df-4c0c-f243-a68041a19302"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf_idf = TfidfVectorizer(analyzer = cleaneddata)\n",
        "tfidf1 = tf_idf.fit_transform(Traindataframe['abstract'])\n",
        "tfidf1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6920, 13343)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "HGbfu9JEvMNp",
        "outputId": "663688c2-bac2-47fd-ca5a-4f555f2b735a"
      },
      "source": [
        "tf_idataframe = pd.DataFrame(tfidf1.toarray())\n",
        "tf_idataframe.columns=tf_idf.get_feature_names()\n",
        "tf_idataframe.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>100minute</th>\n",
              "      <th>103minute</th>\n",
              "      <th>10course</th>\n",
              "      <th>10th</th>\n",
              "      <th>10thgrade</th>\n",
              "      <th>10year</th>\n",
              "      <th>10yearold</th>\n",
              "      <th>112minute</th>\n",
              "      <th>12</th>\n",
              "      <th>129minute</th>\n",
              "      <th>12th</th>\n",
              "      <th>12yearold</th>\n",
              "      <th>13th</th>\n",
              "      <th>14yearold</th>\n",
              "      <th>15th</th>\n",
              "      <th>15year</th>\n",
              "      <th>168minute</th>\n",
              "      <th>18yearold</th>\n",
              "      <th>1930s</th>\n",
              "      <th>1940s</th>\n",
              "      <th>1950s</th>\n",
              "      <th>1960s</th>\n",
              "      <th>1970s</th>\n",
              "      <th>1980s</th>\n",
              "      <th>19th</th>\n",
              "      <th>19thcentury</th>\n",
              "      <th>20car</th>\n",
              "      <th>20th</th>\n",
              "      <th>21st</th>\n",
              "      <th>22yearold</th>\n",
              "      <th>24andunders</th>\n",
              "      <th>26yearold</th>\n",
              "      <th>2day</th>\n",
              "      <th>30</th>\n",
              "      <th>34th</th>\n",
              "      <th>37minute</th>\n",
              "      <th>3d</th>\n",
              "      <th>3yearolds</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>yuen</th>\n",
              "      <th>yung</th>\n",
              "      <th>yvan</th>\n",
              "      <th>zaidan</th>\n",
              "      <th>zany</th>\n",
              "      <th>zap</th>\n",
              "      <th>zaza</th>\n",
              "      <th>zboys</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealously</th>\n",
              "      <th>zeitgeist</th>\n",
              "      <th>zelda</th>\n",
              "      <th>zellweger</th>\n",
              "      <th>zemeckis</th>\n",
              "      <th>zen</th>\n",
              "      <th>zero</th>\n",
              "      <th>zerodimensional</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zhao</th>\n",
              "      <th>zhuangzhuang</th>\n",
              "      <th>zigzag</th>\n",
              "      <th>zing</th>\n",
              "      <th>zinger</th>\n",
              "      <th>zingerfilled</th>\n",
              "      <th>zip</th>\n",
              "      <th>zipper</th>\n",
              "      <th>zippy</th>\n",
              "      <th>zishe</th>\n",
              "      <th>ziyi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombieland</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoning</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zwick</th>\n",
              "      <th>zzzzzzzzz</th>\n",
              "      <th>élan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.048154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.029784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.049596</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.048782</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 13343 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             100minute  103minute  10course  ...  zoom  zwick  zzzzzzzzz  élan\n",
              "0  0.000000        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "1  0.048154        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "2  0.029784        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "3  0.049596        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "4  0.048782        0.0        0.0       0.0  ...   0.0    0.0        0.0   0.0\n",
              "\n",
              "[5 rows x 13343 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2JLBW2SR6L4",
        "outputId": "7001ea4a-b8b2-437e-faa9-06b28ca29a1c"
      },
      "source": [
        "Test_tfidf = tf_idf.transform(Testdataframe['abstract'])\n",
        "print(Test_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1821, 13343)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxWlxWLjMzrZ",
        "outputId": "11ac6732-2a30-4e13-9c00-c3393288ddf2"
      },
      "source": [
        "DT1 = DT.fit(train1,train2)\n",
        "FDT = DT1.predict(test1)\n",
        "print('Acc_result %s' % accuracy_score(FDT,test2))\n",
        "print(classification_report(test2,FDT))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_result 0.6625722543352601\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.63      0.64       671\n",
            "           1       0.66      0.70      0.68       713\n",
            "\n",
            "    accuracy                           0.66      1384\n",
            "   macro avg       0.66      0.66      0.66      1384\n",
            "weighted avg       0.66      0.66      0.66      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXaPVVwWE_tc"
      },
      "source": [
        "MNB = MultinomialNB()\n",
        "SVM = LinearSVC()\n",
        "KNN = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
        "DT = DecisionTreeClassifier()\n",
        "RF = RandomForestClassifier()\n",
        "XGB = XGBClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB-i2mTFwnoW"
      },
      "source": [
        "train1, test1, train2, test2 = train_test_split(tfidf1, Traindataframe['Sentiment'].values,\n",
        "                                                test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqvKfZ9ZAc8e"
      },
      "source": [
        "MNB1 = MNB.fit(train1,train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhOaNNYcFxtb",
        "outputId": "1493c56a-32c2-4cfe-8eb9-fa2788320330"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "FMNB = MNB1.predict(test1)\n",
        "print('Acc_result %s' % accuracy_score(FMNB,test2))\n",
        "print(classification_report(test2,FMNB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_result 0.7955202312138728\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       671\n",
            "           1       0.76      0.88      0.82       713\n",
            "\n",
            "    accuracy                           0.80      1384\n",
            "   macro avg       0.80      0.79      0.79      1384\n",
            "weighted avg       0.80      0.80      0.79      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u0EpMyKHTbS",
        "outputId": "97066683-f4a4-4679-e7ef-37d001cdb419"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "result = cross_val_score(MNB, test1, test2, cv=10)\n",
        "print(\"MNB_given\",result.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB_given 0.7247054530288813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2GbhFBzI72f",
        "outputId": "c461f3d7-9eb5-4576-dea9-8d5eb9f2d527"
      },
      "source": [
        "SVM1 = SVM.fit(train1,train2)\n",
        "FSVM = SVM1.predict(test1)\n",
        "print('Acc_result %s' % accuracy_score(FSVM,test2))\n",
        "print(classification_report(test2,ESVM))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_result 0.791907514450867\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.75      0.78       671\n",
            "           1       0.78      0.83      0.80       713\n",
            "\n",
            "    accuracy                           0.79      1384\n",
            "   macro avg       0.79      0.79      0.79      1384\n",
            "weighted avg       0.79      0.79      0.79      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sao44mRIKhA_",
        "outputId": "24e021d4-532f-4f24-93da-aa84c9da5322"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "result = cross_val_score(SVM, test1, test2, cv=10)\n",
        "print(\"SVM_given\",result.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM_given 0.7348034615785632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2rOOc4MLEPj",
        "outputId": "6cdab810-8d29-4877-cce1-85bdd7e4be63"
      },
      "source": [
        "KNN1 = KNN.fit(train1,train2)\n",
        "FKNN = KNN1.predict(test1)\n",
        "print('Acc_result %s' % accuracy_score(FKNN,test2))\n",
        "print(classification_report(test2,FKNN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_result 0.740606936416185\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.71      0.73       671\n",
            "           1       0.74      0.77      0.75       713\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.74      0.74      0.74      1384\n",
            "weighted avg       0.74      0.74      0.74      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Be3akG6MXfe",
        "outputId": "42cbcf8b-e312-40d3-d13f-f9f2efe6bd52"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "result = cross_val_score(KNN, test1, test2, cv=10)\n",
        "print(\"KNN_given\",result.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN_given 0.6675737670732979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKh2e6LyOP4r",
        "outputId": "7d50759b-e2c2-47f9-fa3d-11c7ec826d01"
      },
      "source": [
        "XGB1 = XGB.fit(train1,train2)\n",
        "FXGB = XGB1.predict(test1)\n",
        "result = cross_val_score(XGB, test1, test2, cv=10)\n",
        "print('Acc_result %s' % accuracy_score(FXGB,test2))\n",
        "print(classification_report(test2,FXGB))\n",
        "print(\"XGB_given\",result.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_result 0.6488439306358381\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.41      0.53       671\n",
            "           1       0.61      0.88      0.72       713\n",
            "\n",
            "    accuracy                           0.65      1384\n",
            "   macro avg       0.68      0.64      0.62      1384\n",
            "weighted avg       0.68      0.65      0.63      1384\n",
            "\n",
            "XGB_given 0.6198884370764259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpl0_YceNW-B",
        "outputId": "465603fc-ed69-4541-a417-00cd07fb64f2"
      },
      "source": [
        "result = cross_val_score(DT, test1, test2, cv=10)\n",
        "print(\"DT_given\",result.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT_given 0.6141174017307892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qGUD8EHNoqK",
        "outputId": "ae0a724b-5de3-4d92-cddb-95f6b5efcf82"
      },
      "source": [
        "RF1 = RF.fit(train1,train2)\n",
        "FRF = RF1.predict(test1)\n",
        "result = cross_val_score(RF, test1, test2, cv=10)\n",
        "print('Acc_result %s' % accuracy_score(FRF,test2))\n",
        "print(classification_report(test2,FRF))\n",
        "print(\"RF_given\",result.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_result 0.7434971098265896\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.68      0.72       671\n",
            "           1       0.73      0.80      0.76       713\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.75      0.74      0.74      1384\n",
            "weighted avg       0.75      0.74      0.74      1384\n",
            "\n",
            "RF_given 0.6827494526118236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj4YmMGlQPXi",
        "outputId": "4d8d0e18-5e3a-4a01-e09c-99b95cb54c1d"
      },
      "source": [
        "Test_MNB = MNB1.predict(Test_tfidf)\n",
        "print('Acc_result %s' % accuracy_score(Test_MNB,Testdataframe['Sentiment']))\n",
        "print(classification_report(Test_MNB,Testdataframe['Sentiment']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_result 0.7940691927512356\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.87      0.77       729\n",
            "           1       0.89      0.74      0.81      1092\n",
            "\n",
            "    accuracy                           0.79      1821\n",
            "   macro avg       0.79      0.81      0.79      1821\n",
            "weighted avg       0.81      0.79      0.80      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBquxyzXTJAV",
        "outputId": "30fe7559-a401-4215-e1ee-eaf0f2a373b4"
      },
      "source": [
        "Test_SVM = SVM1.predict(Test_tfidf)\n",
        "print('Acc_result %s' % accuracy_score(Test_SVM,Testdataframe['Sentiment']))\n",
        "print(classification_report(Test_SVM,Testdataframe['Sentiment']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_result 0.7869302580999451\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       838\n",
            "           1       0.83      0.77      0.79       983\n",
            "\n",
            "    accuracy                           0.79      1821\n",
            "   macro avg       0.79      0.79      0.79      1821\n",
            "weighted avg       0.79      0.79      0.79      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyXeRyWwDodr"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K means, \n",
        "DBSCAN,\n",
        "Hierarchical clustering. \n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV6ZYHHXDodr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf10908b-3164-4f53-a0ba-0564ac5cd091"
      },
      "source": [
        "import pandas as pd\n",
        "import gensim\n",
        "Df=pd.read_csv(\"/content/Amazon_Unlocked_Mobile.csv\")\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "Df = Df[Df['Reviews'].notnull()]\n",
        "df = Df\n",
        "stop = stopwords.words('english')\n",
        "Df['puncless'] = Df['Reviews'].str.replace('[^\\w\\s].#','')\n",
        "Df['mstopwords'] =Df['puncless'].apply(lambda i: \" \".join(i for i in i.split() if i not in stop))\n",
        "Df['numbers']=Df['mstopwords'].str.replace('[0-9]','')\n",
        "Df['lowest'] =Df['numbers'].apply(lambda i: \" \".join(i.lower() for i in i.split()))\n",
        "\n",
        "Df['stemming']=Df['lowest'].apply(lambda i: \" \".join([st.stem(word) for word in i.split()]))\n",
        "Df['freshdata'] = Df['stemming'].apply(lambda i: \" \".join([Word(word).lemmatize() for word in i.split()]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyKhaLHWkwGW",
        "outputId": "d8e2de12-599c-46ce-ac6e-f450703141dd"
      },
      "source": [
        "print(Df['freshdata'].head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    i feel lucki found use (phone u & use hard all...\n",
            "1    nice phone, nice grade pantach revue. veri cle...\n",
            "2                                            veri plea\n",
            "3      it work good goe slow sometim good phone i love\n",
            "4    great phone replac lost phone. the thing volum...\n",
            "Name: freshdata, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPEcnO3vk87Q"
      },
      "source": [
        "Df1=(df.sample(n=4000)).reset_index()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOKsw4HfpMwJ",
        "outputId": "b19b9eb4-5095-4334-a650-168f128fe07c"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf_idf = TfidfVectorizer()\n",
        "tfidf_result = tf_idf.fit_transform(Df1['freshdata'].values)\n",
        "print(tfidf_result.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4000, 4811)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKomqi_Aqa4X",
        "outputId": "6e6f3d89-39b5-4fd1-fe4f-61913e12da14"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "Mtf_idf = KMeans(n_clusters = 5, n_jobs = -1,random_state=99)\n",
        "Mtf_idf.fit(tfidf_result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=5, n_init=10, n_jobs=-1, precompute_distances='auto',\n",
              "       random_state=99, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inVn7wp-8Xp4"
      },
      "source": [
        "tfidf_labelling = Mtf_idf.labels_\n",
        "tfidf_clustering=Mtf_idf.cluster_centers_"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "PPww2zGq86h9",
        "outputId": "921407da-f88f-4c65-f593-adbef75a0666"
      },
      "source": [
        "variables = tf_idf.get_feature_names()\n",
        "variables[1:5]\n",
        "Df1['tf_idf cluster labelling'] = tfidf_labelling\n",
        "Df1.head(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>puncless</th>\n",
              "      <th>mstopwords</th>\n",
              "      <th>numbers</th>\n",
              "      <th>lowest</th>\n",
              "      <th>stemming</th>\n",
              "      <th>freshdata</th>\n",
              "      <th>tf_idf cluster labelling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27982</td>\n",
              "      <td>Apple iPhone 5c 32GB - Unlocked - (Green)</td>\n",
              "      <td>Apple</td>\n",
              "      <td>224.77</td>\n",
              "      <td>3.0</td>\n",
              "      <td>the phone is unlocked thats good, but not is o...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>the phone is unlocked thats good, but not is o...</td>\n",
              "      <td>phone unlocked thats good, 8GB 5GB</td>\n",
              "      <td>phone unlocked thats good, GB GB</td>\n",
              "      <td>phone unlocked thats good, gb gb</td>\n",
              "      <td>phone unlock that good, gb gb</td>\n",
              "      <td>phone unlock that good, gb gb</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10370</td>\n",
              "      <td>Apple iPhone 4 A1332 32GB Black (GSM Unlocked)</td>\n",
              "      <td>Apple</td>\n",
              "      <td>75.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The phone works perfect. My son loved it!!! th...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The phone works perfect. My son loved it!!! th...</td>\n",
              "      <td>The phone works perfect. My son loved it!!! sh...</td>\n",
              "      <td>The phone works perfect. My son loved it!!! sh...</td>\n",
              "      <td>the phone works perfect. my son loved it!!! sh...</td>\n",
              "      <td>the phone work perfect. my son love it!!! ship...</td>\n",
              "      <td>the phone work perfect. my son love it!!! ship...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47297</td>\n",
              "      <td>Apple iPhone 5s 64GB (Gold) -T-Mobile</td>\n",
              "      <td>Apple</td>\n",
              "      <td>265.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The iphone is unlock Good phone but bad ime att</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The iphone is unlock Good phone but bad ime att</td>\n",
              "      <td>The iphone unlock Good phone bad ime att</td>\n",
              "      <td>The iphone unlock Good phone bad ime att</td>\n",
              "      <td>the iphone unlock good phone bad ime att</td>\n",
              "      <td>the iphon unlock good phone bad ime att</td>\n",
              "      <td>the iphon unlock good phone bad ime att</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70917</td>\n",
              "      <td>Apple iPhone 6S Plus Unlocked Smartphone, 32 G...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>749.99</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Good</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60766</td>\n",
              "      <td>Apple iPhone 6 Plus Unlocked Cellphone, 16GB, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>490.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>100% Great seller. No problems what so ever an...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100% Great seller. No problems what so ever an...</td>\n",
              "      <td>100% Great seller. No problems ever im pleased</td>\n",
              "      <td>% Great seller. No problems ever im pleased</td>\n",
              "      <td>% great seller. no problems ever im pleased</td>\n",
              "      <td>% great seller. no problem ever im pleas</td>\n",
              "      <td>% great seller. no problem ever im plea</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... tf_idf cluster labelling\n",
              "0  27982  ...                        0\n",
              "1  10370  ...                        1\n",
              "2  47297  ...                        0\n",
              "3  70917  ...                        4\n",
              "4  60766  ...                        0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiuKFA5QAC1k",
        "outputId": "b6cf6199-d475-4557-8e6e-46f736510c16"
      },
      "source": [
        "Df1.groupby(['tf_idf cluster labelling'])['freshdata'].count()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf_idf cluster labelling\n",
              "0    3179\n",
              "1     231\n",
              "2     280\n",
              "3     108\n",
              "4     202\n",
              "Name: freshdata, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZk4arrFCehM",
        "outputId": "f83a4ee0-719f-49c7-8aac-7934c3932565"
      },
      "source": [
        "centers = Mtf_idf.cluster_centers_.argsort()[:, ::-1]\n",
        "for a in range(1,5):\n",
        "    print(\"Cluster %d:\" % a, end='')\n",
        "    for ind in centers[a, :7]:\n",
        "        print(' %s' % variables[ind], end='')\n",
        "        print()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 1: love\n",
            " it\n",
            " phone\n",
            " great\n",
            " daughter\n",
            " iphon\n",
            " thank\n",
            "Cluster 2: great\n",
            " work\n",
            " phone\n",
            " product\n",
            " price\n",
            " it\n",
            " condition\n",
            "Cluster 3: excel\n",
            " product\n",
            " condit\n",
            " phone\n",
            " condition\n",
            " good\n",
            " thank\n",
            "Cluster 4: good\n",
            " veri\n",
            " it\n",
            " phone\n",
            " work\n",
            " product\n",
            " thank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHMvcjT3EOJo",
        "outputId": "bba04510-9d1f-446c-b523-f27dfd618bd8"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "a=0\n",
        "list=[]\n",
        "for b in Df1['freshdata'].values:\n",
        "    list.append(b.split())\n",
        "wmword = gensim.models.Word2Vec(list,size=100, workers=4)\n",
        "import numpy as np\n",
        "vectors = [];\n",
        "for b in list:\n",
        "    vector1 = np.zeros(100)\n",
        "    count = 0;\n",
        "    for w in b:\n",
        "        try:\n",
        "            vector2 = wmword.wv[w]\n",
        "            vector1 += vector2\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    vector1 /= count\n",
        "    vectors.append(vector1)\n",
        "vectors = np.array(vectors)\n",
        "vectors = np.nan_to_num(vectors)\n",
        "vectors.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2AR-I7AIXpo"
      },
      "source": [
        "Reference - Lower_Bound,Upper_Bound: https://gist.github.com/m00nlight/0f9306b4d4e61ba0195f\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhggFwkJQxds"
      },
      "source": [
        "points = 2 * 100\n",
        "def lower_bound(num, reach): \n",
        "    l, u = 0, len(num) - 1\n",
        "    while l <= u: \n",
        "        c = int(l + (u - l) / 2)\n",
        "        if num[c] >= reach:\n",
        "            u = c - 1\n",
        "        else:\n",
        "            l = c + 1\n",
        "    return l\n",
        "\n",
        "def computing (i, text): \n",
        "    distances = []\n",
        "    for v in text:\n",
        "        distance = np.sum((i - v) **2 ) \n",
        "        if(len(distances) == 200 and distances[199] > distance): \n",
        "            l = int(lower_bound(distances, distance))\n",
        "            if l < 200 and l >= 0 and distances[l] > distance:\n",
        "                distances[l] = distance\n",
        "        else:\n",
        "            distances.append(distance)\n",
        "            distances.sort()\n",
        "    \n",
        "    return distances[199]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvpeHNPJS-iY"
      },
      "source": [
        "neighbour = []\n",
        "for v in vectors[:500]:\n",
        "    neighbour.append(computing(v, vectors[:500]) )\n",
        "neighbour.sort()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "S2JEUkNIUIu7",
        "outputId": "6105af30-ec92-43b5-88c0-e01230080fcc"
      },
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.title(\"Method\")\n",
        "plt.plot([i for i in range(len(neighbour))], neighbour)\n",
        "plt.xlabel(\"all the points\")\n",
        "plt.ylabel(\"Distance of neighbour\")\n",
        "plt.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Z1AGG0IcWyYD",
        "outputId": "1b9c3468-58d1-4b0d-d4ae-1468b8b897fe"
      },
      "source": [
        "design = DBSCAN(eps = 8, min_samples = points, n_jobs=-2)\n",
        "design.fit(vectors)\n",
        "Df1['WMword design'] = design.labels_\n",
        "Df1.head(4)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>puncless</th>\n",
              "      <th>mstopwords</th>\n",
              "      <th>numbers</th>\n",
              "      <th>lowest</th>\n",
              "      <th>stemming</th>\n",
              "      <th>freshdata</th>\n",
              "      <th>tf_idf cluster labelling</th>\n",
              "      <th>WMword design</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27982</td>\n",
              "      <td>Apple iPhone 5c 32GB - Unlocked - (Green)</td>\n",
              "      <td>Apple</td>\n",
              "      <td>224.77</td>\n",
              "      <td>3.0</td>\n",
              "      <td>the phone is unlocked thats good, but not is o...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>the phone is unlocked thats good, but not is o...</td>\n",
              "      <td>phone unlocked thats good, 8GB 5GB</td>\n",
              "      <td>phone unlocked thats good, GB GB</td>\n",
              "      <td>phone unlocked thats good, gb gb</td>\n",
              "      <td>phone unlock that good, gb gb</td>\n",
              "      <td>phone unlock that good, gb gb</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10370</td>\n",
              "      <td>Apple iPhone 4 A1332 32GB Black (GSM Unlocked)</td>\n",
              "      <td>Apple</td>\n",
              "      <td>75.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The phone works perfect. My son loved it!!! th...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The phone works perfect. My son loved it!!! th...</td>\n",
              "      <td>The phone works perfect. My son loved it!!! sh...</td>\n",
              "      <td>The phone works perfect. My son loved it!!! sh...</td>\n",
              "      <td>the phone works perfect. my son loved it!!! sh...</td>\n",
              "      <td>the phone work perfect. my son love it!!! ship...</td>\n",
              "      <td>the phone work perfect. my son love it!!! ship...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47297</td>\n",
              "      <td>Apple iPhone 5s 64GB (Gold) -T-Mobile</td>\n",
              "      <td>Apple</td>\n",
              "      <td>265.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The iphone is unlock Good phone but bad ime att</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The iphone is unlock Good phone but bad ime att</td>\n",
              "      <td>The iphone unlock Good phone bad ime att</td>\n",
              "      <td>The iphone unlock Good phone bad ime att</td>\n",
              "      <td>the iphone unlock good phone bad ime att</td>\n",
              "      <td>the iphon unlock good phone bad ime att</td>\n",
              "      <td>the iphon unlock good phone bad ime att</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70917</td>\n",
              "      <td>Apple iPhone 6S Plus Unlocked Smartphone, 32 G...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>749.99</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Good</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... WMword design\n",
              "0  27982  ...             0\n",
              "1  10370  ...             0\n",
              "2  47297  ...             0\n",
              "3  70917  ...             0\n",
              "\n",
              "[4 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "pou1LlJMYn2I",
        "outputId": "cf1394c4-b264-4f91-fbae-2aea98f9d510"
      },
      "source": [
        "import scipy\n",
        "from scipy.cluster import hierarchy\n",
        "Dendogram = hierarchy.dendrogram(hierarchy.linkage(vectors,method='ward'))\n",
        "plt.axhline(y=10)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7f47d9d87c90>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD7CAYAAACYLnSTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbcElEQVR4nO3df4xl5X3f8fd3Zn+wsGQXzHi9ZiGLiLHlpnisTmmCLe2U1ClyUcGC2mErQi1Xk8p1Cwoq2LSWnaq02GoMbtVEHoKzyPI4QcQpFknTbAljC9WyM5uOfwA2/olgM+yuMbvsssvu7My3f5zn4T5z99x7z/098+znJY3uvec853m+5znP/Z4f99y55u6IiMjaNjLsAEREpHtK5iIiGVAyFxHJgJK5iEgGlMxFRDKwbpCNXXTRRb5z585BNikisubt27fvZ+4+1qxM5WRuZqPAHLDf3a8zs8uAPwLeAOwDbnH3U83q2LlzJ3Nzc1WbFBERwMyea1WmncsstwHPJK8/Bdzn7r8EvAx8qL3wRESkVyolczPbAfwT4A/CawOuAR4JRR4CbuhHgCIi0lrVI/P7gTuB5fD6DcBhdz8dXr8AXNzj2EREpKKWydzMrgMOuvu+ThowsykzmzOzuUOHDnVShYiItFDlyPxdwD81s59SfOB5DfBZYKuZxQ9QdwD7yxZ292l3n3D3ibGxph/GiohIh1omc3f/mLvvcPedwG8Af+Xu/xx4ArgpFLsVeLRvUYqISFPdfGnoLuC3zeyHFNfQH+xNSCIi0q62vjTk7rPAbHj+Y+Cq3ockIiLtGug3QFPT0zAzM6zWJRe7d8PU1LCjEBm+of1vlpkZmJ8fVuuSg/l5HRCIREM7MgcYH4fZ2WFGIGvZ5OSwIxBZPfRfE0VEMqBkLiKSASVzEZEMKJmLiGRAyVxEJANK5iIiGVAyFxHJgJK5iEgGlMxFRDKgZC4ikgElcxGRDCiZi4hkQMlcRCQDSuYiIhlQMhcRyUDLZG5m55jZN83sW2b2lJn9Tpi+x8x+Ymbz4W+8/+GKiEiZKj9OcRK4xt2Pmdl64Ekz+19h3r9z90f6F56IiFTRMpm7uwPHwsv14c/7GZSIiLSn0jVzMxs1s3ngILDX3b8RZt1jZt82s/vMbGODZafMbM7M5g4dOtSjsEVEJFUpmbv7kruPAzuAq8zsl4GPAW8D/j5wIXBXg2Wn3X3C3SfGxsZ6FLaIiKTaupvF3Q8DTwDXuvuCF04Cfwhc1Y8ARUSktSp3s4yZ2dbwfBPwHuB7ZrY9TDPgBuC7/QxUREQaq3I3y3bgITMbpUj+D7v7Y2b2V2Y2BhgwD/yrPsYpIiJNVLmb5dvAO0umX9OXiEREpG36BqiISAaUzEVEMqBkLiKSASVzEZEMKJmLiGRAyVxEJANK5iIiGVAyFxHJgJK5iEgGlMxFRDKgZC4ikgElcxGRDCiZi4hkQMlcRCQDSuYiIhlQMhcRyYCSuYhIBpTMRUQyUOUHnc8xs2+a2bfM7Ckz+50w/TIz+4aZ/dDM/tjMNvQ/XBERKVPlyPwkcI27vwMYB641s18BPgXc5+6/BLwMfKh/YYqISDMtk7kXjoWX68OfA9cAj4TpDwE39CVCERFpqdI1czMbNbN54CCwF/gRcNjdT4ciLwAXN1h2yszmzGzu0KFDvYhZRETqVErm7r7k7uPADuAq4G1VG3D3aXefcPeJsbGxDsMUEZFm2rqbxd0PA08AvwpsNbN1YdYOYH+PYxMRkYqq3M0yZmZbw/NNwHuAZyiS+k2h2K3Ao/0KUkREmlvXugjbgYfMbJQi+T/s7o+Z2dPAH5nZfwL+H/BgH+MUEZEmWiZzd/828M6S6T+muH4uIiJDpm+AiohkQMlcRCQDSuYiIhlQMhcRyYCSuYhIBpTMRUQyoGQuIpIBJXMRkQxU+QaodGN6GmZmhh1FnubvLx4nbx9uHLnavRumpoYdhVSkZN5vMzMwPw/j48OOJDuz40rifTM/Xzwqma8ZSuaDMD4Os7PDjkKkusnJYUcgbdI1cxGRDCiZi4hkQMlcRCQDSuYiIhlQMhcRyYCSuYhIBqr8BuglZvaEmT1tZk+Z2W1h+ifNbL+ZzYe/9/Y/XBERKVPlPvPTwB3u/jdmdj6wz8z2hnn3uft/7V94IiJSRZXfAF0AFsLzo2b2DHBxvwMTEZHq2rpmbmY7KX7c+Rth0kfM7Ntm9nkzu6DHsYmISEWVk7mZbQb+BLjd3V8Bfh+4HBinOHL/3QbLTZnZnJnNHTp0qAchi4hIvUrJ3MzWUyTyL7r7lwHc/YC7L7n7MvAAcFXZsu4+7e4T7j4xNjbWq7hFRCRR5W4WAx4EnnH3zyTTtyfF3gd8t/fhiYhIFVXuZnkXcAvwHTML/xeTu4GbzWwccOCnwG/1JUIREWmpyt0sTwJWMuvPex+OiIh0Qt8AFRHJgJK5iEgGlMxFRDKgZC4ikgElcxGRDCiZi4hkQMlcRCQDSuYiIhlQMhcRyYCSuYhIBpTMRUQyoGQuIpIBJXMRkQwomYuIZEDJXEQkA0rmIiIZUDIXEcmAkrmISAaq/KDzJWb2hJk9bWZPmdltYfqFZrbXzH4QHi/of7giIlKmypH5aeAOd3878CvAvzaztwMfBR5397cAj4fXIiIyBC2TubsvuPvfhOdHgWeAi4HrgYdCsYeAG/oVpIiINNfWNXMz2wm8E/gGsM3dF8KsF4FtDZaZMrM5M5s7dOhQF6GKiEgjlZO5mW0G/gS43d1fSee5uwNetpy7T7v7hLtPjI2NdRWsiIiUq5TMzWw9RSL/ort/OUw+YGbbw/ztwMH+hCgiIq1UuZvFgAeBZ9z9M8msrwC3hue3Ao/2PjwREaliXYUy7wJuAb5jZvNh2t3AvcDDZvYh4Dng/f0JUUREWmmZzN39ScAazP613oYjIiKd0DdARUQyoGQuIpIBJXMRkQwomYuIZEDJXEQkA0rmIiIZUDIXEcmAkrmISAaUzEVEMqBkLiKSASVzEZEMKJmLiGRAyVxEJANK5iIiGVAyFxHJgJK5iEgGlMxFRDKgZC4ikoEqP+j8eTM7aGbfTaZ90sz2m9l8+Htvf8MUEZFmqhyZ7wGuLZl+n7uPh78/721YIiLSjpbJ3N2/Bvx8ALGIiEiH1nWx7EfM7DeBOeAOd3+5rJCZTQFTAJdeemkXzYlkZnoaZmaGHUW5+fnicXJyqGE0tXs3TE0NO4pVo9MPQH8fuBwYBxaA321U0N2n3X3C3SfGxsY6bE4kQzMztaS52oyPF3+r1fz86t0RDklHR+bufiA+N7MHgMd6FpHI2WR8HGZnhx3F2rOazxiGpKMjczPbnrx8H/DdRmVFRKT/Wh6Zm9mXgEngIjN7AfgEMGlm44ADPwV+q48xiohICy2TubvfXDL5wT7EIiIiHdI3QEVEMqBkLiKSASVzEZEMKJmLiGRAyVxEJANK5iIiGVAyFxHJgJK5iEgGlMxFRDKgZC4ikgElcxGRDCiZi4hkQMlcRCQDSuYiIhlQMhcRyYCSuYhIBpTMRUQyUOVn4z4PXAccdPdfDtMuBP4Y2Enxs3Hvd/eX+xemiGRlehpmZjpffn6+eOzmh51374apqc6XX2WqHJnvAa6tm/ZR4HF3fwvweHgtIlLNzEwtIXdifLz469T8fHc7k1Woym+Afs3MdtZNvp7iR54BHgJmgbt6GJeI5G58HGZnh9N2N0f0q1TLZN7ANndfCM9fBLZVWejHh17lA5/7OgALby+mfeBzHUawVrz9A8VjWG+R153NY2PY6z7s9vug6w9A3d0BbzTfzKbMbM7M5hYXF7ttTkRESliRi1sUKi6zPJZ8APp9YNLdF8xsOzDr7m9tVc/ExITPzc0BtbOcYZ1lDcxZs6LStrN5bAx73YfdfpvMbJ+7TzQr0+mR+VeAW8PzW4FHO6xHRER6oMqtiV+i+LDzIjN7AfgEcC/wsJl9CHgOeH8/g+xKt7dAdasXt1B1I7Pbr0SkXJW7WW5uMOvXehxLf8RboLq5jakbw2oXajsSJXOR7HV6N8vaMsxboIYpw9uvRKScvs4vIpIBJXMRkQwomYuIZEDJXEQkA0rmIiIZUDIXEcmAkrmISAaUzEVEMqBkLiKSASVzEZEMKJmLiGRAyVxEJANK5iIiGVAyFxHJgJK5iEgGlMxFRDKgZC4ikoGufmnIzH4KHAWWgNOtfj1aRET6oxc/G/cP3f1nPajn7DDIH5ge9I9J68ejZVC6fR91+95YhWNdl1kGLf7A9CCMjw/uB6Xn5we3kxLp9n3UzXtjlY71bo/MHfhLM3Pgc+4+XV/AzKaAKYBLL720y+YykeMPTOvHo2XQhvU+WqVjvdtk/m53329mbwT2mtn33P1raYGQ4KcBzr/sfJ/cMwnA/Iv3AzC55/YVFe7+u7uZ+nur6/RFRGS16yqZu/v+8HjQzP4UuAr4WqPyJxZPvP58/KO3nzF//sXitEnJXESkPR0nczM7Dxhx96Ph+a8D/7HZMpvWb2L2X8w2nB+P2kVEpD3dHJlvA/7UzGI9M+7+Fz2JSkRE2tJxMnf3HwPv6GEsIiLSId2aKCKSgV58aUgkP4P4ctcgvtS1Cr/cIv2hI3ORMoP4cle/v9S1Sr/cIv2hI3ORRtb6l7tW45db4hlPelais4eeUDIXkcGJiTyekcSkrmTeNSVzERms9IxnNZ49rFFrN5lX/YCqnQ+ZdLonImvU2v0AtOoHVFU/ZNKHRSKyhq2aI/PpfdOv/2+W6X3T1f4/Sy8/oNLpnoisYasmmc98Z2bFc/2zrSHo5t7qDP/Zv5xl+nHpFgY2tldNMgcYf9OAfkhBytXfadCObu6X1h0N5Yb9azqwOnayZf3QaN26ibfq+G9nrA9wbK+qZC6rwDDurdYlrnLd7Fyh+y8krZadbFk/lK1bL+Lt9fgf4Ng+u5N5uscv29OvhqMSObsN84tLq2knW6UfVlO8Q3B2J/N0j1+/p6+yl+/kNLjTU1/tWESkibM7mUPjPX6VZNvJaXAnp76r5XS3He3s6FbpB0rSR/paf8+tjWQ+qA9A0vZi/dPTzesbxGnwWjx9bGdHN4wPlFrtbKrsYJR8OteLr/XXb8Oz/FLpqkjm8R7zjes2cvL0Sbadt21lgUF+ABLbS5+fJYOh5/qxo+vVjq3VzqbVDmYtni2VabZT6/cOLY6PePA0P9/eEXr9NuzkUmkvdNqHPd7RrIpkPvOdGY6cPMIWtnDk5BGg5ItDg/wAZGGh9nx+vvXReS9086ZqZ1D0Y+C1c+bUqq5W9dfX24tk0olejbVhJlNovlPr9Q4tJu1t22D79pUxxPbarbNsG9aPl0ZjpVdH9p30YR92NObunS9sdi3wWWAU+AN3v7dZ+fMvO9+P/uToimnT+6a5c++dHDl5hFEbZcPoBk6cPsGuX9zF7KndK6+rjY833yBpuahsY9Rfr6uvd906WFqCXbuKMm98I7z5zWeuUFl7jdpsZXKys9vQ4jLNklJ9Hx05Alu2FK/r31iphQU4cKBWPsZWv36NYo/Lp+rripr1WX39ZXG16vNGb9xWY6Vs2XaXb6bT7R5j6PbsJyauVnX0og8mJ+GrXy3eV9Hs7Mpke+edxfNPf7qoZ3r6zGkxnji9fvuX9WlZX7Xq+6r9W6UPq4w/aNh/ZrbP3SeahdFxMjezUeBZ4D3AC8BfAze7+9ONllm3Y52ffuH0imlv/e9v5dmfP4thOLVYbvvWJu7/C+DECRgZgYsugoMHYXQU3OHyy8EMfvITWFws3tQbN8LJk3D0KCwvFxWNjhbLr1sHV10FO3bAY48ViWDr1iJRP/tsUXb9ejj33GIeFMucTuIdGSna3Ly5lgQXFuD554s4R0eLncCWLcX8Awdqj/UDLm7chQX40Y+KaRs2FDEuLBR1x/L1A+Gb34RTp4ry8TEuF5NnjG93skOMsUCtj9avL9Zzw4Zi/vPPF8/Hx2v1xeWOHSvWb3S0KJOW2779zMHcKsmn22lkpNiu55wD999fTItxHz9elHOHa64ptnesd2Gh2H6bNhV9ce65RV1pMoj1HDlSxA61bXjwYBFHXK/Nm1duq5g04o4j3e6xTzZsKLb/pk3F89j/cbtDMe5eeGHl9tu8ubb90m2T9unu3bW+aLVsfF22003HUKzj8stXjpe0/fply/og3ZZQ69/Nm4t+ecMbivdj3BYXXACHDxfbJ75Xbr4ZvvzlIu6NG+Gll2rvoeuuK+adOFHUv2VLra44trZtK7b/FVfAHXesPEj79KdrfRfX+fd+b+XYin1mBm96UzHO4vsRinmXXHLme7j+AKl+W5jBxATs3buy/6644sy+O3aseF2fO5L2+p3MfxX4pLv/4/D6YwDu/l8aLvNm8y3/dsuKacdOHWPJl84o+8QfwuRzHYU2OFu21BJ/KiaMpTPX6/Xl0sSYlquft3lzrY10XlXpmysu1yjuRss3W5f6dlJxkNZPr9p2I7EfYr0xiTTqx/i63XYbLVO2Herbb1RHWblGy9Yv36hcq+mdrHtZvfWvd+0qjrRbrUP9enTSXnyevidaxVe1nXbLN9um9fPiGXD9urfTd7t2YV/9al+T+U3Ate7+L8PrW4B/4O4fqSs3BcTzhrcC3++oQRGRs9cvuvtYswJ9/wDU3aeB6X63IyJyNuvm/5nvBy5JXu8I00REZMC6SeZ/DbzFzC4zsw3AbwBf6U1YIiLSjo4vs7j7aTP7CPC/KW5N/Ly7P9WzyEREpLKu7jMXEZHVYe3+BqiIiLxOyVxEJANK5iIiGej7feZm9l7g14F/RHEr4w+ATcClwKvAa+H1RsCAUxT/HuCSEN+5wAIwBhwP5UeBDcByeL4MnAMsheU3A4uhrIc6loGjwPnAAYpbKS1MPxTqeyUs/2KYfwVwOtQxEp6PAidDLOeEGJdDXR5iOB5iiPW/FsothfZHwrwDYb03hLoWQ7e9DFwc2vsZsCXUMxLq8VDnxlDmpTDvgjD/WFjmcGhnc5h/IqzrBeH1aFj+dCgf+3ZT6IcRYH2Iezk8Euo5N8Qd+3wxvH4R2BnqWk7aWQ7txHjC10MZCfPWhXmEcnFcEPqT0M4x4LKwDV4BfiGU/WGyvc4L9Tq1bXteiHEx1Bv76XngbSHGl8LrvxPKeYj1dCh7nGIcxq+0nkzW6WfA1tBfy6EfLgj9dCJMN4rbd88DDoZ214V6D1KM+RHgbynG31JoY32I+dXQXhwzsb9irKeBnwMXhWVGQ98shrIjFGNuayhPiO8l4MJQ5yi192Hsw5fD42JYJ0L9r4XnR4HtocxhirFEWP7VUNfRsK1GgHmKMbIYYt0flt8U2krH8VKIKb6PLSy3nPRBfI9tDe0thT4i9Os6attsXdJG+Hozp0NdhDY3hDbOCX+EdXgtvD5J7T18IiyznmJsHKbYnvFfv54Isf9CaPulsNw5Yd7pJJ4xavnl1fD3t8D/BB5w91doou8fgJqZPmEVEenOZ9z9jmYFBnGZZXkAbYiI5MqpnWk0NIj/Z/51iksGb6Z2Chp3Ik5xirKR4tQonubF08JFilOORWqXW3aE8mk98Xl6OWQpPMZLE6PJ/Pi4FJ7H1/GyTTx99aSeeDoX1yFaH8rFU7Zlaqew8fJL7GdP5sfTXkvKW/hbSqYvhnLxEghh/Y+HPkkv/ywBTwOXUzsdPC/Mj5dnlpN6ong6vxjWh+R57MtY/3nULhnE+OK6xEsC8ZJSbC+e9p4MZTdQnI5emLQft/uGpD/iNklfx3rjpasNyXL12+01ilPVbcn0eHkqXjqKl5HidvKknuW6Op3i1DhexjsZ+jnGF8dOLLeJlds6XroYTZZJ24vzY9uxPkumv0Zte20J8+q3Z9oHsa04Rpeojbv08uCp0IdxPMX1iZfH4mWcc5M6olPhMV6uifEvUnuvrqf2XozbK46NU9Qulcaxk653jH+J2viMYyteRkr7NY6LWEdafl2yfrH9kaSdU9Qu70Xxss5xapfo4rrEfiRpi6TeOM5GqY3n+r6Ll1fPo7Y9Yp2vAPcAX6CFQVxmWWSV/AiGiMgadY+7/4dmBQZxmaXsqEFERKo73qrAIJL596l9Gp5q9bpMqzKe/EHtFL2T0w9v83mvlNVZ1majcunfcpNyzdrupt+axdMqhnbaa1a2WR+1o0objZ5XHSdp+WbLNKq3WT9WjausrXbfn+ky7bxHyta71fhspUqbnWhnLEfLdWWq9nna1tPA3lbB6TKLiMjq5sC/cff/0azQII7MG7WhWxZFRKrZ2qrAoI6Y08Sd3r3RaUKPdaR1NStX/7xsXownfV4/r1kMjdpq1G76yXejtpqtX6t1b1Wu0XpVqa/Rcs3Wu1E9aV2Ntmt9n7WKuaztVsuWjYdUq+1fpZ1OtkXV7VxWttV4avW6flqVda36nmxne1Spt5n693fV8VNlvJW9n9NlquSqVuvqVDjwHuTlD2vwvNv6WtXVrN1mr1uVLYuh0fLttNtq2VYxtVuu023RaLlOtnPZMp32SasynfZFle3fr/bb2UatYml3LLZavmod7dTXab2tVM0Z9WXaWZ9my3e6rkZx22JTg0jmx0Mg9fdXxg8G4r2wsHKl679sZOEv3r8Z91b19wKX1VPWsY2+zFS2h43tpK/LjuIaHdnHOEbqysb5ZXvxtL647HJduXRa/TqU9UWcVn+vf6Plndq9xum8NLayo4qluulx+y5R3Pcdv1od+7F+m6T3Fsc605jS14vU7p9O/yVA/Xaqjz0tU99uGk/aT3HdRuuWKbvPOG0nbb/sKC4tW38kVz92nTPHSJzXqN76MdToSLWszWZHk43qKFsuvcc6vb+97CgUan1cP8bKckMaRxpflTPtstdlfVAW50jdvLLvvZRty/rxVzZG0+eL1P6VRmPu3tc/ih9zfh/Fje//h+Lm9yeBG4FbgJFQ7kbg+vB8hOK+yrL6dgF3hTL/DXiCYsM/ANyYlLk6lLkS+Djw4eT1nyXtPADcnbx+EnhXeP7bwN3AZBLjlcCuJJ77Qtl/DzwSln0AuB64F/jPwJ6w/j8EbgrxPRimj4fH54DPhjY+GOZfHebfE9cttBnXfxJ4JEy7Mpl/ddKvd4dyHw5tXxn6bTLUcxPwjlhPi215NXBDePxnwJ+Fx+uBL8XtFtpIY7ixfhuGxy+Esu8GfpD08T3ADeH1HcDjoV/fHfr4buCmtO6S2O4JdV0fyt8Vpj0AzCaxfJDaWLk36a+Ph+XjNroa2BOW+Xi6fPL8ymTbjFCMzZEQw42h3i+E1x8M/b4H+M1Q7kbg3vQ9ULden0jWq76Pvwg8Su298PWwLh9Op4WyNwD/N7TxcKhzBHgyzB+leB+k74sHKMZtfI/eFmIfJRmfZds96d+rk+32haSfzhh7yTZ7d9xmYb13EcY6yZhvsPzVwEeBvwQ+RTF29hByS6gvxha30Uiyja4P2+geSvJR7I/w+A7ge8DtoY5vAQ8n/X1P2P73pLGzMpdcGeK+Punz0jxY9qcfpxARyYD+Ba6ISAaUzEVEMqBkLiKSASVzEZEM/H8QaMw/csjJewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNTLWdJ2aPk-",
        "outputId": "85f3da2c-632d-4a7c-af22-31dfcc950b76"
      },
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "clustering_analysis = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')  \n",
        "Agg = clustering_analysis.fit_predict(vectors)\n",
        "Df1['WMword cluster'] = clustering_analysis.labels_\n",
        "Df1.head(6)\n",
        "Df1.groupby(['WMword cluster'])['freshdata'].count()\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WMword cluster\n",
              "0    1315\n",
              "1     139\n",
              "2     412\n",
              "3    1202\n",
              "4     141\n",
              "5     532\n",
              "6     259\n",
              "Name: freshdata, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFQwj9vMbPAR",
        "outputId": "40554bf6-acb3-4dbc-cd1a-462df65313de"
      },
      "source": [
        "for a in range(6):\n",
        "    print(\"sentence\", a) #reviews assigned to cluster\n",
        "    print(Df1.iloc[Df1.groupby(['WMword cluster']).groups[a][0]]['freshdata'])\n",
        "    print(Df1.iloc[Df1.groupby(['WMword cluster']).groups[a][1]]['freshdata'])\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence 0\n",
            "phone unlock that good, gb gb\n",
            "the iphon unlock good phone bad ime att\n",
            "sentence 1\n",
            "+++++\n",
            "estafa horribl\n",
            "sentence 2\n",
            "thi phone lock i got even though say un-locked.\n",
            "work great\n",
            "sentence 3\n",
            "the phone work perfect. my son love it!!! shipment realli fast problem activ it. thank you!!! awesome!!\n",
            "% great seller. no problem ever im plea\n",
            "sentence 4\n",
            "great!\n",
            "great!\n",
            "sentence 5\n",
            "thi item iphon box box reseal weird black tape ear bud charger box box japanes horribl fraud\n",
            "i bought wife soon move t-mobil at&t. i usual fear buy expens electron anyon besid manufactur cell phone provider, one work great far.i deduct star sinc i specif chose one said includ charger end included. small issu howev i'm alreadi save much money phone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-q-OGSkDods"
      },
      "source": [
        "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ2_wyBplXhj"
      },
      "source": [
        "K-means clustering is an alogorithm where the attributes and features are classified into k number of groups.Here, K is a positive integer and the sum of the squares of the distance is grouped\n",
        "by minimising them and the centroid cluster. This clustering is the most used in the present industry and it computes fast than any other clustering techniques but it doesn't give the same result \n",
        "everytime since the resulting clusters depends on the initial random assignments. K means simply minimizes the variance in a cluster called as SSE(Sum of squared errors).DBscan is a density\n",
        "based non-parametric clustering algorithm. The set of points are grouped together which are closely packed marking as outliers in low-density region. Hierarchical clustering is an unsupervised \n",
        "technique that gives successive clustering based on previously established clusters. Agglomerative is the on of the hierarchical clustering alogorithm which begins each one into seperate clusters \n",
        "and then merges into larger one. In this clustering method, the elements are grouped based on the distance between the each cluster\n"
      ]
    }
  ]
}